{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65187772",
   "metadata": {
    "id": "YcaRGcNBvcVb"
   },
   "source": [
    "# ASR Tool Access\n",
    "\n",
    "The tool can be accessed from the following link [kanyekuthi-asr-tool](https://huggingface.co/spaces/kanyekuthi/kanyekuthi-dsn_afrispeech) and the model information can be found [kanyekuthi-model-information](https://huggingface.co/kanyekuthi/dsn_afrispeech)\n",
    "\n",
    "The tool can also be accessed from the transformers library using the example script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ad4f10",
   "metadata": {
    "id": "zvbc8oxzttnN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb259b5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "N_J5HS9PtxfM",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e06cd33b-d101-43f5-ec9e-82553dca811a"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not load model kanyekuthi/dsn_afrispeech with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCTC'>, <class 'transformers.models.auto.modeling_auto.AutoModelForSpeechSeq2Seq'>, <class 'transformers.models.whisper.modeling_whisper.WhisperForConditionalGeneration'>).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mautomatic-speech-recognition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkanyekuthi/dsn_afrispeech\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\__init__.py:779\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;66;03m# Infer the framework from the model\u001b[39;00m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# Forced if framework already defined, inferred if it's None\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# Will load the correct model if possible\u001b[39;00m\n\u001b[0;32m    778\u001b[0m model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 779\u001b[0m framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    780\u001b[0m     model,\n\u001b[0;32m    781\u001b[0m     model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    782\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    783\u001b[0m     framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    784\u001b[0m     task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    787\u001b[0m )\n\u001b[0;32m    789\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    790\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\base.py:271\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    273\u001b[0m framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.engine.training.Model\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(inspect\u001b[38;5;241m.\u001b[39mgetmro(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m framework, model\n",
      "\u001b[1;31mValueError\u001b[0m: Could not load model kanyekuthi/dsn_afrispeech with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCTC'>, <class 'transformers.models.auto.modeling_auto.AutoModelForSpeechSeq2Seq'>, <class 'transformers.models.whisper.modeling_whisper.WhisperForConditionalGeneration'>)."
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"kanyekuthi/dsn_afrispeech\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e6cac",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951463e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKoHCsZEt33D",
    "outputId": "4ca64131-00c1-4e81-c2cb-e507b7dfa959"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# audio file 1 (Human)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m transcribe \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masr.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m,chunk_length_s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(transcribe[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m][:\u001b[38;5;241m500\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "# audio file 1 (Human)\n",
    "transcribe = pipe(\"asr.mp4\",chunk_length_s=30)\n",
    "print(transcribe[\"text\"][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d3014",
   "metadata": {},
   "source": [
    "Hello, so we just like to use this audio for testing purposes. We are using it to test the transcription tool that Kanyi has developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599341a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tl4YPvK0w6wP",
    "outputId": "2253ce0f-0fea-4936-d544-7a7ec049b62b"
   },
   "outputs": [],
   "source": [
    "# audio file 2 (Human)\n",
    "transcribe = pipe(\"whatsapp_test.ogg\",chunk_length_s=30)\n",
    "print(transcribe[\"text\"][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9908d3cb",
   "metadata": {},
   "source": [
    "Hey this is just a test audio to basically just check if the transcription tool is working. I was wondering if we can use this just to see what the transcription would look like. Let me know if it works it needs to be shorter than 30 seconds. Thank you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b704c2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvIy5HQ-xEed",
    "outputId": "c28dbf13-b6a6-4b01-a49c-eb4bc1737d9e"
   },
   "outputs": [],
   "source": [
    "# audio file 3 (Automated Voice)\n",
    "transcribe = pipe(\"automatic_speech.mp3\",chunk_length_s=30)\n",
    "print(transcribe[\"text\"][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6871bde6",
   "metadata": {},
   "source": [
    "Automatic speech recognition means converting spoken language to written text allowing for textual analysis, search and processing of spoken content."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "source_map": [
   14,
   22,
   29,
   41,
   45,
   55,
   59,
   69,
   73,
   83
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}