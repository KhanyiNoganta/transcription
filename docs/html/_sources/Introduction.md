# Introduction

Automatic Speech Recognition (ASR) has immense significance in a wide range of applications, including transcription services, voice assistants, and language technologies {cite}`li2022recent`. Nonetheless, conventional ASR systems encounter notable difficulties when it comes to precisely transcribing speech with African
accents {cite}`khandelwal2020black, yemmene2019motivations`. The challenges associated with the development and implementation of Automatic Speech Recognition (ASR) systems are particularly noteworthy when African languages and accents are considered. African accents exhibit discernible phonetic patterns, fluctuations in intonation, and disparities in lexical utilization, all of which may lead to suboptimal transcription outcomes {cite}`tivadar2017speech`. This phenomenon can be attributed primarily to the extensive range of intonations present, which encompasses a diverse array of dialects and variants {cite}`badenhorst2019usefulness, badenhorst2017limitations`. To address these challenges, the utilization of transfer learning has emerged as a promising approach for adapting pre-existing models to particular domains or accents {cite}`vsvec2022transfer`. This technique aims to enhance the accuracy and resilience of automatic speech recognition (ASR) systems {cite}`vsvec2022transfer`

Whisper transformers are a specific category of ASR (Automatic Speech Recognition) models that employ the transformer architecture {cite}`radford2022robust`. The models underwent rigorous training using annotated audio transcription data. These models exhibit a notable capacity to accurately transcribe speech without requiring additional training on specific tasks or domains, and have exhibited notable achievements in diverse natural language processing tasks {cite}`radford2022robust`. Nonetheless, limited research conducted on the extent to which African accents can be accurately and effectively captured by ASR systems, as well as the performance of these systems in handling the intricacies and nuances associated with these accents.

The performance of Whisper transformers is assessed in both their pre-trained state and when subjected to fine-tuning through transfer learning, specifically on African-accented speech data. A pre-existing speech dataset that contains African-accented English is employed. This dataset has been specifically created to facilitate research on automatic speech recognition (ASR) for languages in Africa that have limited resources. By conducting a thorough assessment, we analyzed the efficacy of transfer learning-based Whisper transformers and the transcription accuracy was quantified using the Word Error Rate (WER) metric.

Although transfer learning has been extensively researched in the field of ASR {cite}`wang2015transfer, ko2015audio`, its specific implementation in African accents has received limited attention {cite}`olatunji2023afrinames`. This task endeavors to address the existing research gap by examining the effectiveness of transfer learning using Whisper transformers. The aim of this task is to make a valuable contribution to the advancement of automatic speech recognition (ASR) systems that are both more precise and inclusive, specifically designed to cater to the requirements of African language communities.  
